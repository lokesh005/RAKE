{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "### Please go through https://somegreymatters.wordpress.com/2016/12/08/sentiment-and-emotion-analysis-of-tweets-regarding-demonetization/\n",
    "You can see tags associated with the post (Tags: analysis, blackmoney, demonetization, emotion, noteban, sentiment, twitter). Your task is to re-generate these tags and maybe some more relevant ones for the same blog post using NLP/ML techniques in the programming language you are comfortable working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "#for pulling data out of HTML and XML files.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#HTTP library for pulling pushing and authenticating\n",
    "import requests\n",
    "\n",
    "#for Regular expression operations\n",
    "import re\n",
    "\n",
    "#comparison, addition, greater than less then\n",
    "import operator\n",
    "\n",
    "#system calls, deal with user arguments\n",
    "import sys\n",
    "\n",
    "#list of common stop words various languages like the\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Web scraping to fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP_LIST::', \"['nirmal', 'kumar', 's,', 'sakthi', 'balan', 'm,', 'pushkal', 'agarwal,', 'lokesh', 'todwal', 'department', 'computer', 'science', 'engineering,', 'lnmiit,', 'jaipur,', 'india', 'collected', 'tweets', 'regarding', 'three', 'hashtags', 'blackmoney,', 'indiafightscorruption,', 'blackmoneycleanup', 'th', 'november', 'th', 'november', '.', 'got', 'around', '.', 'lakh', 'tweets', 'blackmoney', 'posted', 'around', 'users,', 'around', 'lakh', 'tweets', 'indiafightscorruption', 'posted', 'around', 'users,', 'around', 'tweets', 'blackmoneycleanup', 'posted', 'around', 'users.', 'makes', 'total', 'around', '.', 'lakh', 'tweets', 'posted', 'around', '.', 'lakh', 'users.', 'entire', 'tweets', 'blackmoneycleanup', 'representative', 'random', 'sample', 'total', 'tweets', 'two', 'hashtags', 'taken', 'analysis.', 'outcomes', 'analysis.', 'number', 'tweets', 'positive,', 'negative', 'neutral', 'polarities', 'given', 'table', 'plotted', 'figure', '.', 'table', 'polaritywise', 'distribution', 'tweets', 'polarity', 'negative', 'figure', 'plot', 'polaritywise', 'distribution', 'tweets', 'positive', 'dominant', 'polarity.', 'means', 'majority', 'people', 'tweeted', 'favor', 'demonetization.', 'second', 'dominant', 'polarity', 'negative,', 'number', 'tweets', 'negative', 'polarity', 'less', 'half', 'tweets', 'positive', 'polarity.', 'interestingly,', 'hashtags', 'show', 'trend.', 'number', 'tweets', 'show', 'different', 'emotions', 'given', 'table', 'plotted', 'figure', '.', 'tweets', 'show', 'characteristic', 'emotions.', 'considering', 'tweets', 'showed', 'six', 'emotions', 'proposed', 'paul', 'ekman.', 'widely', 'accepted', 'basic', 'human', 'emotions.', 'table', 'emotionwise', 'distribution', 'tweets', 'emotion', 'anger', 'disgust', 'fear', 'figure', 'emotionwise', 'distribution', 'tweets', 'here,', 'can', 'see', 'dominant', 'emotion', 'joy', 'second', 'dominant', 'emotion', 'anger.', 'again,', 'number', 'tweets', 'express', 'anger', 'far', 'less', '(much', 'less', 'half)', 'number', 'tweets', 'express', 'joy.', 'also,', 'three', 'hashtags', 'show', 'trend.', 'number', 'positive,', 'negative', 'neutral', 'tweets', 'tweets', 'emotion', 'blackmoney,', 'indiafighytscorruption', 'blackmoneycleanup', 'shown', 'tables', ',', 'respectively.', 'plotted', 'figures', ',', 'respectively.', 'table', 'polaritywise', 'distribution', 'emotional', 'tweets', 'blackmoney', 'negative', 'figure', 'polaritywise', 'distribution', 'emotional', 'tweets', 'blackmoney', 'table', 'polaritywise', 'distribution', 'emotional', 'tweets', 'indiafightscorruption', 'negative', 'figure', 'polaritywise', 'distribution', 'emotional', 'tweets', 'indiafightscorruption', 'table', 'polaritywise', 'distribution', 'emotional', 'tweets', 'blackmoneycleanup', 'negative', 'figure', 'polaritywise', 'distribution', 'emotional', 'tweets', 'blackmoneycleanup', 'here,', 'can', 'see', 'dominant', 'combination', 'positive', 'joy', 'three', 'hashtags.', 'however,', 'case', 'second', 'dominant', 'combination,', 'hashtags', 'show', 'different', 'trends.', 'second', 'dominant', 'combination', 'negative', 'joy', 'blackmoney,', 'neutral', 'joy', 'indiafightscorruption', 'neutral', 'anger', 'blackmoneycleanup.', 'fill', 'details', 'click', 'icon', 'log', 'in:', 'commenting', 'using', 'wordpress.com', 'account.', '(', 'log', 'change', ')', 'commenting', 'using', 'twitter', 'account.', '(', 'log', 'change', ')', 'commenting', 'using', 'facebook', 'account.', '(', 'log', 'change', ')', 'commenting', 'using', 'google', 'account.', '(', 'log', 'change', ')', 'connecting', 's', 'notify', 'new', 'comments', 'via', 'email.']\")\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get the words\n",
    "def getWordList(url):\n",
    "    word_list = []\n",
    "    #raw data\n",
    "    source_code = requests.get(url)\n",
    "    #convert to text\n",
    "    plain_text = source_code.text\n",
    "    #lxml format\n",
    "    soup = BeautifulSoup(plain_text,'lxml')\n",
    "\n",
    "    #find the words in paragraph tag\n",
    "    for text in soup.findAll('p'):\n",
    "        if text.text is None:\n",
    "            continue\n",
    "        #content\n",
    "        content = text.text\n",
    "        #lowercase and split into an array\n",
    "        words = content.lower().split()\n",
    "\n",
    "        #for each word\n",
    "        for word in words:\n",
    "            #remove non-chars\n",
    "            cleaned_word = clean_word(word)\n",
    "            #if there is still something there\n",
    "            if len(cleaned_word) > 0:\n",
    "                #add it to our word list\n",
    "                word_list.append(cleaned_word)\n",
    "\n",
    "    return word_list\n",
    "\n",
    "\n",
    "#clean word with regex\n",
    "def clean_word(word):\n",
    "    cleaned_word = re.sub('[0-9#/+/%/-]+', '', word)\n",
    "    return cleaned_word\n",
    "\n",
    "url = \"https://somegreymatters.wordpress.com/2016/12/08/sentiment-and-emotion-analysis-of-tweets-regarding-demonetization/\"\n",
    "\n",
    "#try-except block. simple way to deal with exceptions \n",
    "#great for HTTP requests\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    page_word_list = getWordList(url)\n",
    "    stop_words = get_stop_words('en')\n",
    "\n",
    "    temp_list = [] #to get word list present on website\n",
    "    for word in page_word_list:\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(str(word))\n",
    "    print(\"TEMP_LIST::\", str(temp_list))\n",
    "    print(len(temp_list))\n",
    "    text = \" \".join(str(x) for x in temp_list)\n",
    "    \n",
    "#throw an exception in case it breaks\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"The server didn't respond. Please, try again later.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nirmal kumar s, sakthi balan m, pushkal agarwal, lokesh todwal department computer science engineering, lnmiit, jaipur, india collected tweets regarding three hashtags blackmoney, indiafightscorruption, blackmoneycleanup th november th november . got around . lakh tweets blackmoney posted around users, around lakh tweets indiafightscorruption posted around users, around tweets blackmoneycleanup posted around users. makes total around . lakh tweets posted around . lakh users. entire tweets blackmoneycleanup representative random sample total tweets two hashtags taken analysis. outcomes analysis. number tweets positive, negative neutral polarities given table plotted figure . table polaritywise distribution tweets polarity negative figure plot polaritywise distribution tweets positive dominant polarity. means majority people tweeted favor demonetization. second dominant polarity negative, number tweets negative polarity less half tweets positive polarity. interestingly, hashtags show trend. number tweets show different emotions given table plotted figure . tweets show characteristic emotions. considering tweets showed six emotions proposed paul ekman. widely accepted basic human emotions. table emotionwise distribution tweets emotion anger disgust fear figure emotionwise distribution tweets here, can see dominant emotion joy second dominant emotion anger. again, number tweets express anger far less (much less half) number tweets express joy. also, three hashtags show trend. number positive, negative neutral tweets tweets emotion blackmoney, indiafighytscorruption blackmoneycleanup shown tables , respectively. plotted figures , respectively. table polaritywise distribution emotional tweets blackmoney negative figure polaritywise distribution emotional tweets blackmoney table polaritywise distribution emotional tweets indiafightscorruption negative figure polaritywise distribution emotional tweets indiafightscorruption table polaritywise distribution emotional tweets blackmoneycleanup negative figure polaritywise distribution emotional tweets blackmoneycleanup here, can see dominant combination positive joy three hashtags. however, case second dominant combination, hashtags show different trends. second dominant combination negative joy blackmoney, neutral joy indiafightscorruption neutral anger blackmoneycleanup. fill details click icon log in: commenting using wordpress.com account. ( log change ) commenting using twitter account. ( log change ) commenting using facebook account. ( log change ) commenting using google account. ( log change ) connecting s notify new comments via email.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Some more relevant tags for the same blog post using NLP/ML technique\n",
    "## (a)Used Rapid Automatic Keyword Extraction (RAKE) algorithm that extracts keywords from text, by identifying runs of non-stopwords and then scoring these phrases across the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isPunct(word):\n",
    "    return len(word) == 1 and word in string.punctuation\n",
    "\n",
    "def isNumeric(word):\n",
    "    try:\n",
    "        float(word) if '.' in word else int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def _generate_candidate_keywords(sentences):\n",
    "    phrase_list = []\n",
    "    stopwords = stop_words = get_stop_words('en') #set(nltk.corpus.stopwords.words())\n",
    "    for sentence in sentences:\n",
    "        words = map(lambda x: \"|\" if x in stopwords else x, nltk.word_tokenize(sentence.lower()))\n",
    "        phrase = []\n",
    "        for word in words:\n",
    "            if not(word == \"|\" and isPunct(word)):\n",
    "                phrase_list.append(word)\n",
    "    return phrase_list\n",
    "\n",
    "\n",
    "def _calculate_word_scores(phrase_list):\n",
    "    word_freq = nltk.FreqDist()\n",
    "    word_degree = nltk.FreqDist()\n",
    "    for phrase in phrase_list:\n",
    "        degree = len(filter(lambda x: not isNumeric(x), phrase)) - 1\n",
    "        for word in phrase:\n",
    "            word_freq[word]+=1\n",
    "            word_degree[word]+= degree # other words\n",
    "    for word in word_freq.keys():\n",
    "        word_degree[word] = word_degree[word] + word_freq[word] # itself\n",
    "        # word score = deg(w) / freq(w)\n",
    "    word_scores = {}\n",
    "    for word in word_freq.keys():\n",
    "        word_scores[word] = word_degree[word] / word_freq[word]\n",
    "    return word_scores\n",
    "\n",
    "def _calculate_phrase_scores(phrase_list, word_scores):\n",
    "    phrase_scores = {}\n",
    "    for phrase in phrase_list:\n",
    "        phrase_score = 0\n",
    "        for word in phrase:\n",
    "            phrase_score += word_scores[word]\n",
    "        phrase_scores[\"\".join(phrase)] = phrase_score\n",
    "    return phrase_scores\n",
    "\n",
    "def extract(text, incl_scores=False):\n",
    "    top_fraction = 1 # consider top third candidate keywords by score\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    phrase_list = _generate_candidate_keywords(sentences)\n",
    "    word_scores = _calculate_word_scores(phrase_list)\n",
    "    phrase_scores = _calculate_phrase_scores(phrase_list, word_scores)\n",
    "    sorted_phrase_scores = sorted(phrase_scores.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    n_phrases = len(sorted_phrase_scores)\n",
    "    print(n_phrases)\n",
    "    if incl_scores:\n",
    "        return sorted_phrase_scores[0:int(n_phrases/top_fraction)]\n",
    "    else:\n",
    "        return map(lambda x: x[0], sorted_phrase_scores[0:int(n_phrases/top_fraction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "127\n",
      "['indiafighytscorruption', 'indiafightscorruption', 'blackmoneycleanup', 'demonetization', 'characteristic', 'representative', 'interestingly', 'distribution', 'polaritywise', 'wordpress.com', 'respectively', 'combination', 'considering', 'engineering', 'emotionwise', 'connecting', 'blackmoney', 'commenting', 'polarities', 'department', 'regarding', 'different', 'collected', 'emotional', 'polarity', 'proposed', 'dominant', 'facebook', 'computer', 'accepted', 'positive', 'emotions', 'outcomes', 'analysis', 'comments', 'majority', 'november', 'negative', 'account', 'science', 'emotion', 'hashtags', 'figures', 'plotted', 'pushkal', 'disgust', 'neutral', 'details', 'twitter', 'notify', 'agarwal', 'around', 'lnmiit', 'random', 'tweeted', 'express', 'however', 'nirmal', 'figure', 'people', 'second', 'number', 'jaipur', 'entire', 'posted', 'widely', 'google', 'trends', 'change', 'sakthi', 'todwal', 'sample', 'tables', 'lokesh', 'click', 'india', 'showed', 'basic', 'tweets', 'using', 'kumar', 'trend', 'favor', 'balan', 'human', 'ekman', 'email', 'total', 'given', 'taken', 'anger', 'table', 'means', 'makes', 'users', 'shown', 'three', 'icon', 'paul', 'plot', 'fill', 'much', 'fear', 'half', 'lakh', 'case', 'also', 'show', 'less', 'can', 'far', 'got', 'via', 'log', 'joy', 'two', 'six', 'new', 'see', 'th', 'm', 's', '(', ',', '.', ':', ')']\n"
     ]
    }
   ],
   "source": [
    "Textracted = extract(text, incl_scores=True)\n",
    "Fextracted = extract(text)\n",
    "print(Fextracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_fraction = 1 # consider top third candidate keywords by score\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "phrase_list = _generate_candidate_keywords(sentences)\n",
    "word_scores = _calculate_word_scores(phrase_list)\n",
    "phrase_scores = _calculate_phrase_scores(phrase_list, word_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': 1,\n",
       " ')': 1,\n",
       " ',': 1,\n",
       " '.': 1,\n",
       " ':': 1,\n",
       " 'a': 8,\n",
       " 'b': 9,\n",
       " 'c': 10,\n",
       " 'd': 9,\n",
       " 'e': 7,\n",
       " 'f': 9,\n",
       " 'g': 8,\n",
       " 'h': 7,\n",
       " 'i': 10,\n",
       " 'j': 4,\n",
       " 'k': 9,\n",
       " 'l': 8,\n",
       " 'm': 8,\n",
       " 'n': 9,\n",
       " 'o': 9,\n",
       " 'p': 10,\n",
       " 'r': 9,\n",
       " 's': 7,\n",
       " 't': 8,\n",
       " 'u': 9,\n",
       " 'v': 7,\n",
       " 'w': 6,\n",
       " 'x': 5,\n",
       " 'y': 10,\n",
       " 'z': 14}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_calculate_word_scores(phrase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': 1,\n",
       " ')': 1,\n",
       " ',': 1,\n",
       " '.': 1,\n",
       " ':': 1,\n",
       " 'accepted': 69,\n",
       " 'account': 63,\n",
       " 'agarwal': 55,\n",
       " 'also': 32,\n",
       " 'analysis': 67,\n",
       " 'anger': 41,\n",
       " 'around': 53,\n",
       " 'balan': 42,\n",
       " 'basic': 44,\n",
       " 'blackmoney': 87,\n",
       " 'blackmoneycleanup': 148,\n",
       " 'can': 27,\n",
       " 'case': 32,\n",
       " 'change': 49,\n",
       " 'characteristic': 121,\n",
       " 'click': 47,\n",
       " 'collected': 76,\n",
       " 'combination': 99,\n",
       " 'commenting': 86,\n",
       " 'comments': 66,\n",
       " 'computer': 70,\n",
       " 'connecting': 89,\n",
       " 'considering': 97,\n",
       " 'demonetization': 125,\n",
       " 'department': 83,\n",
       " 'details': 57,\n",
       " 'different': 77,\n",
       " 'disgust': 58,\n",
       " 'distribution': 107,\n",
       " 'dominant': 70,\n",
       " 'ekman': 41,\n",
       " 'email': 41,\n",
       " 'emotion': 60,\n",
       " 'emotional': 76,\n",
       " 'emotions': 67,\n",
       " 'emotionwise': 90,\n",
       " 'engineering': 93,\n",
       " 'entire': 50,\n",
       " 'express': 52,\n",
       " 'facebook': 70,\n",
       " 'far': 26,\n",
       " 'favor': 42,\n",
       " 'fear': 33,\n",
       " 'figure': 52,\n",
       " 'figures': 59,\n",
       " 'fill': 35,\n",
       " 'given': 41,\n",
       " 'google': 49,\n",
       " 'got': 25,\n",
       " 'half': 32,\n",
       " 'hashtags': 60,\n",
       " 'however': 52,\n",
       " 'human': 41,\n",
       " 'icon': 38,\n",
       " 'india': 46,\n",
       " 'indiafightscorruption': 187,\n",
       " 'indiafighytscorruption': 197,\n",
       " 'interestingly': 110,\n",
       " 'jaipur': 50,\n",
       " 'joy': 23,\n",
       " 'kumar': 43,\n",
       " 'lakh': 32,\n",
       " 'less': 29,\n",
       " 'lnmiit': 53,\n",
       " 'log': 25,\n",
       " 'lokesh': 47,\n",
       " 'm': 8,\n",
       " 'majority': 66,\n",
       " 'makes': 39,\n",
       " 'means': 39,\n",
       " 'much': 34,\n",
       " 'negative': 64,\n",
       " 'neutral': 58,\n",
       " 'new': 22,\n",
       " 'nirmal': 52,\n",
       " 'notify': 55,\n",
       " 'november': 65,\n",
       " 'number': 51,\n",
       " 'outcomes': 67,\n",
       " 'paul': 35,\n",
       " 'people': 51,\n",
       " 'plot': 35,\n",
       " 'plotted': 59,\n",
       " 'polarities': 86,\n",
       " 'polarity': 72,\n",
       " 'polaritywise': 102,\n",
       " 'positive': 68,\n",
       " 'posted': 50,\n",
       " 'proposed': 70,\n",
       " 'pushkal': 58,\n",
       " 'random': 52,\n",
       " 'regarding': 77,\n",
       " 'representative': 113,\n",
       " 'respectively': 100,\n",
       " 's': 7,\n",
       " 'sakthi': 49,\n",
       " 'sample': 48,\n",
       " 'science': 60,\n",
       " 'second': 51,\n",
       " 'see': 21,\n",
       " 'show': 29,\n",
       " 'showed': 45,\n",
       " 'shown': 38,\n",
       " 'six': 22,\n",
       " 'table': 40,\n",
       " 'tables': 47,\n",
       " 'taken': 41,\n",
       " 'th': 15,\n",
       " 'three': 38,\n",
       " 'todwal': 48,\n",
       " 'total': 41,\n",
       " 'trend': 42,\n",
       " 'trends': 49,\n",
       " 'tweeted': 52,\n",
       " 'tweets': 43,\n",
       " 'twitter': 56,\n",
       " 'two': 23,\n",
       " 'users': 39,\n",
       " 'using': 43,\n",
       " 'via': 25,\n",
       " 'widely': 50,\n",
       " 'wordpress.com': 101}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_calculate_phrase_scores(phrase_list, word_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Using Word Ranking: It ranks the words of a text file according to their frequency. It puts the words in a dictionary; each word is the key, and the frequency is the value. It then prints the dictionary in ascending order of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets: 27\n",
      ": 16\n",
      "distribution: 10\n",
      "negative: 9\n",
      "polaritywise: 8\n",
      "around: 8\n",
      "table: 7\n",
      "figure: 7\n",
      "dominant: 7\n",
      "blackmoneycleanup: 7\n",
      "number: 6\n",
      "hashtags: 6\n",
      "emotional: 6\n",
      "blackmoney: 6\n",
      "show: 5\n",
      "positive: 5\n",
      "polarity: 5\n",
      "log: 5\n",
      "joy: 5\n",
      "indiafightscorruption: 5\n",
      "using: 4\n",
      "users: 4\n",
      "second: 4\n",
      "posted: 4\n",
      "neutral: 4\n",
      "lakh: 4\n",
      "emotions: 4\n",
      "emotion: 4\n",
      "commenting: 4\n",
      "change: 4\n",
      "anger: 4\n",
      "account: 4\n",
      "three: 3\n",
      "plotted: 3\n",
      "less: 3\n",
      "combination: 3\n",
      "trend: 2\n",
      "total: 2\n",
      "th: 2\n",
      "see: 2\n",
      "s: 2\n",
      "respectively: 2\n",
      "november: 2\n",
      "here: 2\n",
      "half: 2\n",
      "given: 2\n",
      "express: 2\n",
      "emotionwise: 2\n",
      "different: 2\n",
      "can: 2\n",
      "analysis: 2\n",
      "wordpress.com: 1\n",
      "widely: 1\n",
      "via: 1\n",
      "two: 1\n",
      "twitter: 1\n",
      "tweeted: 1\n",
      "trends: 1\n",
      "todwal: 1\n",
      "taken: 1\n",
      "tables: 1\n",
      "six: 1\n",
      "shown: 1\n",
      "showed: 1\n",
      "science: 1\n",
      "sample: 1\n",
      "sakthi: 1\n",
      "representative: 1\n",
      "regarding: 1\n",
      "random: 1\n",
      "pushkal: 1\n",
      "proposed: 1\n",
      "polarities: 1\n",
      "plot: 1\n",
      "people: 1\n",
      "paul: 1\n",
      "outcomes: 1\n",
      "notify: 1\n",
      "nirmal: 1\n",
      "new: 1\n",
      "much: 1\n",
      "means: 1\n",
      "makes: 1\n",
      "majority: 1\n",
      "m: 1\n",
      "lokesh: 1\n",
      "lnmiit: 1\n",
      "kumar: 1\n",
      "jaipur: 1\n",
      "interestingly: 1\n",
      "indiafighytscorruption: 1\n",
      "india: 1\n",
      "in: 1\n",
      "icon: 1\n",
      "human: 1\n",
      "however: 1\n",
      "got: 1\n",
      "google: 1\n",
      "fill: 1\n",
      "figures: 1\n",
      "fear: 1\n",
      "favor: 1\n",
      "far: 1\n",
      "facebook: 1\n",
      "entire: 1\n",
      "engineering: 1\n",
      "email: 1\n",
      "ekman: 1\n",
      "disgust: 1\n",
      "details: 1\n",
      "department: 1\n",
      "demonetization: 1\n",
      "considering: 1\n",
      "connecting: 1\n",
      "computer: 1\n",
      "comments: 1\n",
      "collected: 1\n",
      "click: 1\n",
      "characteristic: 1\n",
      "case: 1\n",
      "basic: 1\n",
      "balan: 1\n",
      "also: 1\n",
      "agarwal: 1\n",
      "again: 1\n",
      "accepted: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = text\n",
    "l = {}\n",
    "for word in text.split():\n",
    "    # make everything lowercase\n",
    "    word = word.lower()\n",
    "    \n",
    "    # check for words in () or []\n",
    "    if word.startswith('[') or word.startswith('('):\n",
    "        word = word[1:]\n",
    "    if word.endswith(']') or word.endswith(')'):\n",
    "        word = word[:-1]\n",
    "        \n",
    "    # check for words that end with punctuation\n",
    "    if word.endswith('.') or word.endswith(',') or word.endswith(';') or word.endswith(':'):\n",
    "        word = word[:-1]\n",
    "    # if word is in dictionary, increment the value\n",
    "    # otherwise add the word to dictionary with value 1\n",
    "    if word in l:\n",
    "        l[word] += 1\n",
    "    else:\n",
    "        l[word] = 1\n",
    "        \n",
    "# this prints the dict out sorted by value\n",
    "for key, value in sorted(l.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    print '%s: %s' % (key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra effort\n",
    "## 3. Function that will be used to find similarity/ relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##LCH_SIMILARITY\n",
    "def sim1(word1, word2, lch_threshold=2.00):\n",
    "    \"\"\"To find words are similar/relevant or not.\n",
    "       lch_threshold: can change it to have different kind of result. More LCH, more is the similarity. \n",
    "                      Value is very application dependent.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for net1 in wn.synsets(word1):\n",
    "        for net2 in wn.synsets(word2):\n",
    "            try:\n",
    "                lch = net1.lch_similarity(net2)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            if lch >= lch_threshold:\n",
    "                results.append([net1, net2])\n",
    "    if not results:\n",
    "        return False\n",
    "    #print(results)\n",
    "    return True\n",
    "\n",
    "\n",
    "##PATH_SIMILARITY\n",
    "def sim2(word1, word2, path_threshold=0.5):\n",
    "    \"\"\"To find words are similar/relevant or not.\n",
    "       lch_threshold: can change it to have different kind of result. More LCH, more is the similarity. \n",
    "                      Value is very application dependent.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for net1 in wn.synsets(word1):\n",
    "        for net2 in wn.synsets(word2):\n",
    "            try:\n",
    "                lch = net1.path_similarity(net2)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            if lch >= path_threshold:\n",
    "                results.append([net1, net2])\n",
    "    if not results:\n",
    "        return False\n",
    "    #print(results)\n",
    "    return True\n",
    "\n",
    "\n",
    "##WUP_SIMILARITY\n",
    "def sim3(word1, word2, wup_threshold=0.5):\n",
    "    \"\"\"To find words are similar/relevant or not.\n",
    "       lch_threshold: can change it to have different kind of result. More LCH, more is the similarity. \n",
    "                      Value is very application dependent.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for net1 in wn.synsets(word1):\n",
    "        for net2 in wn.synsets(word2):\n",
    "            try:\n",
    "                lch = net1.wup_similarity(net2)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if lch >= wup_threshold:\n",
    "                results.append([net1, net2])\n",
    "    if not results:\n",
    "        return False\n",
    "    #print(results)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indiafightscorruption'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags=Fextracted[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::Relevant words from the given document is:::::::::\n",
      "indiafighytscorruption:[]\n",
      "indiafightscorruption:[]\n",
      "blackmoneycleanup:[]\n",
      "demonetization:['change']\n",
      "characteristic:['lakh', 'half', 'favor', 'change', 's', 'number', 'three', 'total', 'figure', 'two', 'six', 'department', 'figures']\n",
      "representative:['details', 'science', 'computer', 'joy', 'neutral', 'case', 'sample']\n"
     ]
    }
   ],
   "source": [
    "print(\"::::::::::::Relevant words from the given document is:::::::::\")\n",
    "for tag in tags:\n",
    "    l=[]\n",
    "    for word in set(temp_list):\n",
    "        if(sim1(tag, word) and tag != word):\n",
    "                l.append(word)\n",
    "    print(tag+\":\"+str(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
